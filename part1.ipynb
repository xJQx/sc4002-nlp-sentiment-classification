{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.24.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.9.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.23.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.22.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: click in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: gensim in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.24.1)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in c:\\users\\cihui\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets\n",
    "%pip install nltk\n",
    "%pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cihui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 8530\n",
      "})\n",
      "validate:  Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 1066\n",
      "})\n",
      "test:  Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 1066\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(\"train: \", train_dataset)\n",
    "print(\"validate: \", validation_dataset)\n",
    "print(\"test: \", test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset into pandas dataframe\n",
    "train_df = train_dataset.to_pandas()\n",
    "val_df = validation_dataset.to_pandas()\n",
    "test_df = test_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cihui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\cihui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\cihui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('treebank')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def preprocessText(dataset):\n",
    "    texts = []\n",
    "\n",
    "    for i in range(0, len(dataset)):\n",
    "        text = re.sub('[^a-zA-Z]', ' ', dataset['text'][i]) #remove numbers and non-alphabetical symbols\n",
    "        text = text.lower() # lower case\n",
    "        text = text.strip()\n",
    "\n",
    "        if isinstance(text, str):    \n",
    "            tokens = nltk.tokenize.word_tokenize(text) \n",
    "        else:     \n",
    "            print(\"Input is not a valid string.\")\n",
    "        #text = nltk.tokenize.word_tokenize(text) # tokenize\n",
    "        \n",
    "        texts.append(tokens)\n",
    "        \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = preprocessText(train_df)\n",
    "val_split = preprocessText(val_df)\n",
    "test_split = preprocessText(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparing Word Embeddings\n",
    "\n",
    "- using `Word2Vec`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load a pretrained word2vec model (trained on Google News dataset contained about 100 billion words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# or maybe this works also, takes around 7 mins to load\\n\\nimport gensim.downloader as api\\n\\ngoogleNews_w2v_model = api.load(\\'word2vec-google-news-300\\')\\ngoogleNews_w2v_model.save(\"googleNews_w2v_model\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "googleNews_w2v_model = gensim.models.KeyedVectors.load_word2vec_format('model\\GoogleNews-vectors-negative300.bin\\GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "# download the pretrained model from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g (take around 1.5GB)\n",
    "\n",
    "'''\n",
    "# or maybe this works also, takes around 7 mins to load\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "googleNews_w2v_model = api.load('word2vec-google-news-300')\n",
    "googleNews_w2v_model.save(\"googleNews_w2v_model\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(googleNews_w2v_model.index_to_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) size of vocabulary from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16331\n"
     ]
    }
   ],
   "source": [
    "trainDataset_words = [word for sentence in train_split for word in sentence]\n",
    "trainDataset_vocabs = set(trainDataset_words)\n",
    "trainDataset_vocab_size = len(trainDataset_vocabs)\n",
    "\n",
    "print(trainDataset_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) number of OOV (out-of-vocabulary) ( those words appeared in the training data but\n",
    "not in the Word2vec dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445\n",
      "['fantasti', 'mamet', 'cassel', 'shimizu', 'stonehenge', 'radcliffe', 'profundamente', 'dickensian', 'mesmerised', 'vonnegut', 'gosford', 'collosum', 'sarandon', 'moretti', 'montias', 'labute', 'zaidan', 'ozpetek', 'endeavour', 'besson', 'pender', 'ballhaus', 'unsalvageability', 'cierta', 'schindler', 'elizabethan', 'runyon', 'arteta', 'interspliced', 'sorprender', 'donati', 'certamente', 'makmalbaf', 'polanski', 'jir', 'pompeo', 'blanchett', 'rhames', 'abrahams', 'pryor', 'charlize', 'desplechin', 'shapelessly', 'tamb', 'addessi', 'grenier', 'kosashvili', 'aprovechar', 'hemmingway', 'cattaneo', 'bergmanesque', 'uzumaki', 'kaputschnik', 'ltimo', 'navajos', 'krige', 'hubac', 'spookies', 'godfrey', 'ryoko', 'komediant', 'criar', 'eisenberg', 'kouyate', 'janey', 'bugsy', 'lanie', 'beavis', 'chouraqui', 'garc', 'abderrahmane', 'flavour', 'crappola', 'arwen', 'tampoco', 'transforma', 'revigorates', 'farrelly', 'wewannour', 'prejuicios', 'torna', 'pinocchio', 'minkoff', 'rmino', 'goldbacher', 'whaley', 'pinochet', 'ghandi', 'jewison', 'girardot', 'compleja', 'fangoria', 'brosnan', 'romanek', 'gilliam', 'adicional', 'achival', 'diciness', 'callie', 'mcculloch', 'arrancar', 'molina', 'westfeldt', 'blethyn', 'rothman', 'hanukkah', 'khouri', 'earnhart', 'stepford', 'solondz', 'battista', 'socrates', 'christophe', 'rifkin', 'thornberrys', 'duvall', 'phonce', 'yvan', 'naipaul', 'alain', 'pulpiness', 'oliveira', 'bierbichler', 'wwii', 'swanson', 'cleanflicks', 'seagal', 'dullingly', 'caulfield', 'orson', 'escapa', 'levar', 'musset', 'derrida', 'weissman', 'depalma', 'satirizado', 'vivi', 'instalment', 'ricture', 'affirmational', 'nebrida', 'convencional', 'germanic', 'cronenberg', 'simbolizando', 'mediocridade', 'gilmore', 'coolidge', 'costner', 'humourless', 'acontecimentos', 'giovanni', 'tartakovsky', 'sendo', 'comedias', 'sandrine', 'unclassifiably', 'justine', 'fassbinder', 'mcfarlane', 'meaningness', 'demme', 'disfrutable', 'shakesperean', 'jagger', 'renoir', 'psychodramatics', 'laurence', 'bobbidi', 'mueller', 'shapiro', 'materalism', 'sabrina', 'quentin', 'ratner', 'fincher', 'kuras', 'emphasising', 'uberviolence', 'unrecommendable', 'sidey', 'rowling', 'hirosue', 'funcionar', 'tarzan', 'kurupt', 'herek', 'glamour', 'moulds', 'rockwell', 'cotswolds', 'devito', 'mullan', 'bettany', 'watstein', 'louiso', 'andys', 'tully', 'everlyn', 'penas', 'maud', 'whitaker', 'parris', 'augustinian', 'herzog', 'ferrera', 'savour', 'theatres', 'paradiso', 'shayamalan', 'unslick', 'garry', 'quido', 'schumacher', 'newfoundland', 'accorsi', 'shakespearean', 'desaponta', 'acabamos', 'auteil', 'jed', 'grato', 'constata', 'akasha', 'versi', 'personajes', 'xfl', 'drippiness', 'lavinia', 'turturro', 'pta', 'retadora', 'amini', 'renner', 'hawley', 'risa', 'goodall', 'kinnear', 'decasia', 'gilligan', 'lillard', 'desarrollarse', 'espet', 'dolgin', 'kingsley', 'cuadro', 'democracie', 'inquestion', 'schweiger', 'gandalf', 'antonia', 'potemkin', 'updatings', 'kubrick', 'piesiewicz', 'divertida', 'cletis', 'rdida', 'igby', 'muniz', 'runteldat', 'kozmo', 'danang', 'stortelling', 'thulani', 'broomfield', 'csokas', 'felinni', 'ncia', 'molony', 'deseos', 'raimondi', 'rechy', 'schiffer', 'kieslowski', 'liman', 'goyer', 'timo', 'piccoli', 'mulholland', 'greaseballs', 'curiosa', 'stima', 'jacobi', 'flatula', 'argento', 'assistir', 'labour', 'sumamente', 'strafings', 'maguire', 'naqoyqatsi', 'woolf', 'iben', 'damme', 'a', 'pootie', 'enfrentar', 'bullwinkle', 'kumble', 'deadeningly', 'unencouraging', 'floria', 'steinberg', 'gabbiest', 'oedekerk', 'schneidermeister', 'audrey', 'premissa', 'zaza', 'ventually', 'francamente', 'coppola', 'hayao', 'sinais', 'dench', 'gellar', 'kahlories', 'shatner', 'godard', 'heidegger', 'condensada', 'charly', 'idemoto', 'manhunter', 'bartlett', 'skolnick', 'senegalese', 'barrymore', 'sanitised', 'tarantino', 'kaige', 'hatfield', 'decter', 'clockstoppers', 'soberbio', 'irwins', 'carnahan', 'esquerdo', 'jarecki', 'ronn', 'abbass', 'bueller', 'puttingly', 'kilner', 'centre', 'pryce', 'overmanipulative', 'beckett', 'talanc', 'gerardo', 'olympus', 'luhrmann', 'sailboaters', 'doris', 'nanook', 'freundlich', 'bardem', 'eroti', 'qutting', 'flakeball', 'grey', 'aaliyah', 'bergman', 'precisamente', 'shankman', 'masterpeice', 'howie', 'jarvis', 'eyre', 'scarpia', 'deblois', 'entretiene', 'mckay', 'mattel', 'wisegirls', 'spinotti', 'preciosista', 'bruckheimer', 'burkina', 'callar', 'quaid', 'marveilleux', 'leplouff', 'ararat', 'cliffsnotes', 'narrativa', 'efteriades', 'palma', 'devos', 'gantz', 'schnieder', 'resnick', 'dumas', 'landbound', 'hatosy', 'jonze', 'anakin', 'ricci', 'shadyac', 'marisa', 'aquel', 'ratliff', 'hitchcock', 'oscura', 'atacar', 'demencial', 'laramie', 'matheson', 'shagster', 'cuaron', 'prewarned', 'revelled', 'colocar', 'morvern', 'plimpton', 'flavours', 'atacarse', 'elie', 'koury', 'abagnale', 'goldmember', 'benoit', 'entretenida', 'meeropol', 'bladerunner', 'guillen', 'denzel', 'contemplarse', 'pasadena', 'marivaux', 'decirles', 'complejos', 'carrey', 'arkin', 'precisa', 'wierzbicki', 'fracasso', 'colosal', 'silberstein', 'perabo', 'joaquin', 'montied', 'grandiosa', 'japanimator', 'morrissette', 'ganha', 'camareras', 'zoolander', 'dilbert', 'entretenimiento', 'ramsay', 'recoing', 'neuwirth', 'monkeyfun', 'ttner', 'chyna', 'auschwitz', 'hunnam', 'sinise', 'ruzowitzky', 'fontaine', 'actuaci', 'fabuleux', 'culkin', 'sissako', 'scorcese', 'inhospitability', 'preocupar', 'truffaut', 'sorimachi', 'depois', 'pellington', 'aproveitar', 'retrata', 'shapable', 'treebeard', 'nijinsky', 'topkapi', 'lyne', 'shreve', 'splatterfests', 'tavernier', 'covardia', 'estava', 'verdu', 'welles', 'raphael', 'tierney', 'schrader', 'baio', 'lohman', 'swimfan', 'abrams', 'sampi', 'cineasts', 'truncheoning', 'ciertos', 'kaos', 'divertido', 'kosminsky', 'mcbeal', 'saudades', 'sonnenfeld', 'testud', 'hinton', 'belinsky', 'pincel', 'parodia', 'outgag', 'caruso', 'hermocrates', 'eurotrash', 'tunisian', 'juliette', 'mcdormand', 'reginald', 'coen', 'realidade', 'josef', 'aburrido', 'carion', 'seigner', 'narcotizing', 'pidamente', 'exibi', 'aiello', 'carlen', 'musicais', 'desee', 'sinta', 'selby', 'bisset', 'stamos', 'dunst', 'unfakable', 'leppard', 'rampling', 'giannini', 'exporing', 'pistoled', 'wiel', 'filmes', 'gibney', 'beatrice', 'enviar', 'leoni', 'volletta', 'twohy', 'nanette', 'siuation', 'ritter', 'tufano', 'glizty', 'cedric', 'paxton', 'eastwood', 'puccini', 'welty', 'kissinger', 'policiales', 'elmore', 'meara', 'hossein', 'rorschach', 'schepisi', 'almodovar', 'jacquot', 'plympton', 'armenia', 'mattei', 'haneke', 'suspeito', 'musclefest', 'muccino', 'harbour', 'carmichael', 'intacto', 'hypertime', 'julianne', 'evolu', 'witherspoon', 'banderas', 'dudsville', 'bernal', 'musker', 'intentando', 'esfera', 'marxian', 'szpilman', 'windtalkers', 'spielberg', 'heremakono', 'niro', 'malkovich', 'bedevilling', 'pokepie', 'cassavetes', 'penotti', 'krawczyk', 'latifah', 'gedeck', 'hjelje', 'elvira', 'tomei', 'strainingly', 'otar', 'shinya', 'adventues', 'unhibited', 'sorvino', 'haynes', 'pasolini', 'gulzar', 'lasker', 'philbin', 'hornby', 'epis', 'englishmen', 'stoppard', 'sontag', 'bleibtreu', 'koyaanisqatsi', 'alagna', 'provocatuers', 'errol', 'ltimos', 'derivativeness', 'javier', 'dahmer', 'roteiro', 'prescinde', 'kiarostami', 'abandone', 'instante', 'famuyiwa', 'shainberg', 'alcatraz', 'bluto', 'cabe', 'fulford', 'ivans', 'powerpuff', 'sandler', 'vinnie', 'akira', 'learnt', 'leontine', 'consegue', 'orqu', 'bogdanovich', 'humour', 'dreamworks', 'mika', 'aborbing', 'redford', 'imponderably', 'gordy', 'gidget', 'rohmer', 'aceitou', 'bigelow', 'franz', 'kafka', 'waydowntown', 'pianista', 'cleopatra', 'yakusho', 'hartley', 'tambi', 'dumbfoundingly', 'jaglomized', 'ploughing', 'pollyana', 'scorsese', 'assayas', 'ssima', 'macgraw', 'cusack', 'leavitt', 'springsteen', 'janklowicz', 'hitchcockianism', 'aviv', 'capturou', 'hannibal', 'oesn', 'wifty', 'breen', 'cockettes', 'walken', 'tsukamoto', 'possui', 'hutchins', 'unemotive', 'banales', 'pascale', 'ringu', 'to', 'and', 'nonethnic', 'splendour', 'bondish', 'qualls', 'tolkien', 'sequer', 'idiomas', 'majid', 'predecible', 'teatral', 'slappingly', 'granger', 'videodrome', 'butterworth', 'danis', 'sayles', 'miike', 'roteirista', 'demeanour', 'kapur', 'leblanc', 'aidan', 'chanukah', 'yimou', 'reggio', 'direto', 'dafoe', 'aragorn', 'patric', 'veronique', 'horton', 'huston', 'cativante', 'blutarsky', 'malone', 'xiaoshuai', 'jelinek', 'hickenlooper', 'fizzability', 'estudo', 'qatsi', 'stuporously', 'tanovic', 'pentacostal', 'ouro', 'fustily', 'reparto', 'nuttgens', 'pabst', 'arquette', 'theron', 'gaghan', 'rubbo', 'poderosa', 'ssimos', 'bruckheimeresque', 'niccol', 'shohei', 'peploe', 'mcmullen', 'scherfig', 'underdramatized', 'brecht', 'orlean', 'russos', 'sitcomishly', 'mendes', 'categorisation', 'audiard', 'crudup', 'waldo', 'pollak', 'perdona', 'magimel', 'lathan', 'mouglalis', 'cinemantic', 'splittingly', 'orwell', 'koepp', 'maryam', 'fresnadillo', 'snazziness', 'hideo', 'dankworth', 'leguizamo', 'kurys', 'clayburgh', 'clearasil', 'alientation', 'reeses', 'ramis', 'shandling', 'miscasts', 'ellefsen', 'idoosyncratic', 'prefeminist', 'epps', 'mccoist', 'dario', 'tashlin', 'iwai', 'lagaan', 'aqueles', 'christelle', 'kirshner', 'nietzsche', 'fleder', 'lilia', 'bornin', 'manqu', 'entreter', 'aboul', 'gaitskill', 'petin', 'macdowell', 'nrelentingly', 'savoca', 'slowtime', 'caddyshack', 'jeanette', 'reeboir', 'nohe', 'puportedly', 'corruscating', 'barlow', 'larson', 'groen', 'gayton', 'cagney', 'dreyfus', 'sommers', 'rusi', 'elemento', 'gosto', 'rinzler', 'shyamalan', 'nikita', 'bartleby', 'genevieve', 'clutchy', 'gutterball', 'wladyslaw', 'malfitano', 'ruggero', 'parton', 'ontiveros', 'autocritique', 'elfriede', 'affleck', 'powaqqatsi', 'shunji', 'francophiles', 'papai', 'cirulnick', 'chabrolian', 'cintas', 'attal', 'emocionante', 'clarissa', 'sandeman', 'visualmente', 'thornberry', 'hitchens', 'crispin', 'raimi', 'actorish', 'equlibrium', 'jagjit', 'saldanha', 'carente', 'etoiles', 'likableness', 'dridi', 'profesores', 'morlocks', 'augustine', 'obviation', 'frida', 'superada', 'picpus', 'hearst', 'taymor', 'verdadera', 'carvey', 'imaginaci', 'pythonesque', 'maelstr', 'schwentke', 'levant', 'laboriousness', 'iditarod', 'kazmierski', 'vulakoro', 'universos', 'vittorio', 'desfecho', 'manipulador', 'veljohnson', 'bradbury', 'tosca', 'notting', 'juwanna', 'mcgrath', 'desnudo', 'fica', 'nakata', 'mcdowell', 'gruelling', 'rintar', 'passo', 'manoel', 'theatre', 'seinfeld', 'longley', 'holofcener', 'neill', 'emocionalmente', 'kasem', 'flck', 'rosenthal', 'mcadams', 'emotiva', 'herrmann', 'liotta', 'colour', 'antwone', 'ferzan', 'fiennes', 'feardotcom', 'andersson', 'jeunet', 'tykwer', 'zemeckis', 'djeinaba', 'bibbidy', 'murdock', 'copmovieland', 'indieflick', 'borchardt', 'uruk', 'stockwell', 'lapaglia', 'salton', 'cardoso', 'berling', 'willams', 'collinwood', 'gainsbourg', 'celebi', 'overstylized', 'coriat', 'flatman', 'estupendamente', 'artsploitation', 'originalidad', 'anspaugh', 'stico', 'cremaster', 'kalesniko', 'schnitzler', 'shiri', 'sico', 'guillermo', 'mergulha', 'aladdin', 'andamento', 'soapdish', 'faso', 'diferen', 'janszen', 'mibii', 'lmica', 'toolbags', 'graceland', 'thurman', 'gulpilil', 'belushi', 'patriotero', 'payami', 'scherick', 'bielinsky', 'pretenciosas', 'giles', 'nalin', 'egoyan', 'emilie', 'cristo', 'sillified', 'allodi', 'naturedness', 'dirigir', 'dirigida', 'mothman', 'armenians', 'fato', 'saeko', 'malle', 'huppert', 'sascha', 'meyjes', 'enfrentados', 'predecesora', 'behaviour', 'estranhos', 'benshan', 'tolstoy', 'grabowsky', 'velma', 'duraci', 'deepa', 'mctiernan', 'hundert', 'statham', 'wilco', 'incoloro', 'untugged', 'culminando', 'generaciones', 'balto', 'addams', 'ziyi', 'townsend', 'mulan', 'jez', 'brockovich', 'incompet', 'serrault', 'miyazaki', 'espectador', 'wachowski', 'steinis', 'ilya', 'beresford', 'macnaughton', 'cantet', 'kaufmann', 'hitchcockian', 'esteticamente', 'andr', 'dogme', 'uwe', 'tambor', 'mullinski', 'abandono', 'fuhrman', 'nesbitt', 'tunney', 'koshashvili', 'chabrol', 'obligada', 'amoses', 'gerbosi', 'necessidade', 'zeus', 'arnie', 'backmasking', 'eudora', 'mehta', 'saigon', 'kline', 'cheech', 'mpaa', 'asay', 'wimmer', 'favour', 'foxworthy', 'sade', 'caviezel', 'hawke', 'phocion', 'titus', 'bailly', 'balzac', 'digno', 'darwinian', 'asbury', 'nenette', 'crummles', 'mcgowan', 'hogwarts', 'margolo', 'achronological', 'persegui', 'estafeta', 'nettelbeck', 'calibre', 'wolodarsky', 'hoult', 'sychowski', 'labours', 'turpin', 'sprecher', 'birot', 'defeatingly', 'gollum', 'higuchinsky', 'bickle', 'desta', 'expresar', 'chaiken', 'salma', 'segal', 'clements', 'eisenstein', 'solondzian', 'villeneuve', 'cavaradossi', 'burstein', 'harland', 'nickleby', 'tulo', 'mirren', 'cuar', 'espectacular', 'flatbush', 'nolden', 'resultan', 'aesop', 'schaeffer', 'aleck', 'jaglom', 'byler', 'sandlerian', 'lynne', 'ihops', 'intelectualmente', 'gantzes', 'olvidar', 'kahlo', 'fillm', 'atreve', 'elegante', 'recurre', 'berkley', 'contando', 'fessenden', 'deutchland', 'yiddish', 'pode', 'byron', 'gheorghiu', 'veggietales', 'bjorkness', 'michell', 'petroni', 'decidiram', 'delicia', 'linklater', 'claud', 'interesantes', 'travil', 'perde', 'macbeth', 'ackerman', 'denlopp', 'iosseliani', 'peralta', 'involvingly', 'chesterton', 'enga', 'grimas', 'makhmalbaf', 'joff', 'verete', 'frustrado', 'longo', 'logra', 'fallas', 'zucker', 'ayres', 'siegel', 'myer', 'takashi', 'hayek', 'zhao', 'samira', 'rembrandt', 'premisa', 'duddy', 'elmer', 'coburn', 'schaefer', 'ecks', 'guzm', 'representando', 'ourside', 'neeson', 'wenders', 'freudianism', 'rymer', 'bille', 'surfacey', 'clancy', 'impotentes', 'tardier', 'redgrave', 'ningu', 'forster', 'fabian', 'yosuke', 'nonchallenging', 'bolado', 'zellweger', 'ahola', 'papin', 'weimar', 'italianas', 'headbangingly', 'vardalos', 'helga', 'superlarge', 'verbinski', 'repellantly', 'unembarrassing', 'cadness', 'mcklusky', 'zzzzzzzzz', 'kurosawa', 'daneses', 'giler', 'helene', 'nicolas', 'tchaikovsky', 'intera', 'friel', 'napoli', 'italicizes', 'uplifter', 'viveka', 'roisterous', 'cipherlike', 'auteuil', 'esfor', 'benigni', 'apallingly', 'mcconaughey', 'montaje', 'juergensen', 'shamu', 'altman', 'arriesgado', 'mesmos', 'stainton', 'zwick', 'minac', 'actuada', 'of', 'endedness', 'apted', 'frodo', 'branagh', 'nticas', 'shlockmeister', 'gymkata', 'jacobson', 'arliss', 'cula', 'cimarron', 'weigel', 'demeo', 'sydow', 'unlaughable', 'gyllenhaal', 'marvellous', 'marcken', 'stagecrafts', 'fascinantes', 'preocupe', 'acaba', 'schweig', 'hotsies', 'igualmente', 'toity', 'enternecedora', 'cacoyannis', 'tautou', 'breckin', 'gianni', 'rosenbaum', 'bogdanich', 'galinsky', 'ecclesiastes', 'artnering', 'niels', 'babbitt', 'spader', 'hashiguchi', 'deje', 'dalloway', 'miedos', 'fuelled', 'sonrisa', 'munchausen', 'dicaprio', 'astoria', 'fantasma', 'razzie', 'espect', 'binks', 'guei', 'delhomme', 'hammily', 'hacerlo', 'choquart', 'jovovich', 'scuzbag', 'clericks', 'gadzooks', 'phifer', 'paulette', 'wollter', 'romijn', 'kieran', 'thandie', 'melville', 'reigen', 'majidi', 'binoche', 'gere', 'inuit', 'stallone', 'oliviera', 'deniro', 'alexandre', 'chekhov', 'gump', 'garbus', 'avary', 'woodard', 'gondry', 'pouqu', 'noyce', 'ferrara', 'viterelli', 'isabelle', 'imamura', 'desplat', 'behan', 'ladr', 'pacino', 'melodram', 'bottomlessly', 'jakob', 'thekids', 'wendigo', 'esther', 'petter', 'nadia', 'diop', 'jiri', 'burdette', 'dogtown', 'soliah', 'corcuera', 'wildean', 'romething', 'kafkaesque', 'menzel', 'hellstenius', 'massoud', 'sincera', 'bazadona', 'mib', 'karmen', 'wahlberg', 'absolutamente', 'complementares', 'schwartzman', 'barris', 'sencillamente', 'personagens', 'explicados', 'werner', 'stica', 'hepburn', 'soderbergh', 'silberling', 'xtc', 'dangerfield', 'hudlin', 'colgate', 'prechewed', 'avventura', 'miramax', 'vh', 'tezuka', 'zhuangzhuang', 'balkans', 'greengrass', 'unconned', 'silbersteins', 'danilo', 'weinstein', 'elegiacally', 'philibert', 'apesar', 'gabriele', 'carlito', 'aurelie', 'uncharismatically', 'amari', 'unplundered', 'kibbitzes', 'burkinabe', 'liyan', 'kilmer', 'gauls', 'milla', 'ribisi', 'movilizador', 'rodrigues', 'pretence', 'unsuspenseful', 'fiorentino', 'griffith', 'almod', 'serry', 'polson', 'sugarman', 'campanella', 'shafer', 'havia', 'droppingly', 'hubert', 'shindler', 'baca', 'alfonso', 'kalvert', 'carlin', 'destinees', 'nachtwey', 'conmovedora', 'besco', 'ryanovich', 'favourite', 'superficiale', 'baran', 'wertmuller', 'byatt', 'spielbergian', 'dateflick', 'zealanders', 'seldahl']\n"
     ]
    }
   ],
   "source": [
    "oov_words = [word for word in trainDataset_vocabs if word not in googleNews_w2v_model]\n",
    "oov_words_size = len(oov_words)\n",
    "\n",
    "print(oov_words_size)\n",
    "print(oov_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) initialize an embedding matrix\n",
    "- handling of OOV words: using the mean vector from the pretrained w2v vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embedding_dim = googleNews_w2v_model.vector_size # 300\n",
    "\n",
    "#initialize embedding matrix (train_data_vocab_size X embedding dimension)\n",
    "embedding_matrix = np.zeros((trainDataset_vocab_size, embedding_dim))\n",
    "\n",
    "#vocab-to-index dict\n",
    "trainDataset_vocab_index = {vocab: i for i, vocab in enumerate(trainDataset_vocabs)}\n",
    "\n",
    "#mean vector of the pretrained w2v\n",
    "w2v_vectors = np.array([googleNews_w2v_model[vocab] for vocab in googleNews_w2v_model.index_to_key])\n",
    "mean_vector = np.mean(w2v_vectors, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in embedding matrix\n",
    "for vocab in trainDataset_vocabs:\n",
    "    #assign mean vector for OOV words\n",
    "    if vocab in oov_words:\n",
    "        embedding_matrix[trainDataset_vocab_index[vocab]] = mean_vector\n",
    "    else:\n",
    "        embedding_matrix[trainDataset_vocab_index[vocab]] = googleNews_w2v_model[vocab]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
