{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Model Training & Evaluation - biLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare embedding matrix and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "embedding_path = Path(\"models/embedding_matrix_oov.npy\")\n",
    "index_from_word_path = Path(\"models/index_from_word_oov.json\")\n",
    "\n",
    "embedding_matrix = np.load(embedding_path)\n",
    "with index_from_word_path.open() as f:\n",
    "    index_from_word = json.load(f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bern/anaconda3/envs/nlp_project_new/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /Users/bern/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to /Users/bern/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/bern/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils.text import tokenize\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = tokenize(dataset[\"train\"])\n",
    "val_dataset = tokenize(dataset[\"validation\"])\n",
    "test_dataset = tokenize(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text import token_to_index\n",
    "\n",
    "train_dataset = token_to_index(dataset=train_dataset, index_from_word=index_from_word)\n",
    "val_dataset = token_to_index(dataset=val_dataset, index_from_word=index_from_word)\n",
    "test_dataset = token_to_index(dataset=test_dataset, index_from_word=index_from_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])\n",
    "val_dataset = val_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])\n",
    "test_dataset = test_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(type=\"torch\")\n",
    "val_dataset.set_format(type=\"torch\")\n",
    "test_dataset.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'original_len', 'indexes'],\n",
       "    num_rows: 8530\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RNN - biLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train import train_rnn_model_with_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieuristic search with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 13:57:56,055] A new study created in memory with name: no-name-b254b3cf-ac55-40ab-b247-24130b48cfb1\n",
      "Seed set to 42\n",
      "/Users/bern/anaconda3/envs/nlp_project_new/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'rnn_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['rnn_model'])`.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/bern/anaconda3/envs/nlp_project_new/lib/python3.11/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name   | Type               | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model  | RNN                | 5.0 M  | train\n",
      "1 | metric | MulticlassAccuracy | 0      | train\n",
      "------------------------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "20.152    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- batch_size_2048; lr_0.001; optimizer_Adagrad; hidden_dim_32; num_layers_3; sentence_representation_last ----------\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bern/anaconda3/envs/nlp_project_new/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bern/anaconda3/envs/nlp_project_new/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 5/5 [01:01<00:00,  0.08it/s, v_num=0, train_loss=0.346, train_acc=0.874, val_loss=0.545, val_acc=0.750]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 14:19:28,389] Trial 0 finished with value: 0.5293257832527161 and parameters: {'hidden_dim': 32, 'num_layers': 3, 'optimizer_name': 'Adagrad', 'batch_size': 2048, 'learning_rate': 0.001, 'sentence_representation_type': 'last'}. Best is trial 0 with value: 0.5293257832527161.\n",
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type               | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model  | RNN                | 7.8 M  | train\n",
      "1 | metric | MulticlassAccuracy | 0      | train\n",
      "------------------------------------------------------\n",
      "7.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.8 M     Total params\n",
      "31.007    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- batch_size_2048; lr_0.1; optimizer_Adagrad; hidden_dim_256; num_layers_2; sentence_representation_last ----------\n",
      "Epoch 7: 100%|██████████| 5/5 [00:52<00:00,  0.10it/s, v_num=0, train_loss=0.587, train_acc=0.649, val_loss=0.785, val_acc=0.561]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 14:29:44,809] Trial 1 finished with value: 0.7769343256950378 and parameters: {'hidden_dim': 256, 'num_layers': 2, 'optimizer_name': 'Adagrad', 'batch_size': 2048, 'learning_rate': 0.1, 'sentence_representation_type': 'last'}. Best is trial 1 with value: 0.7769343256950378.\n",
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type               | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model  | RNN                | 5.4 M  | train\n",
      "1 | metric | MulticlassAccuracy | 0      | train\n",
      "------------------------------------------------------\n",
      "5.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 M     Total params\n",
      "21.576    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- batch_size_2048; lr_0.1; optimizer_Adagrad; hidden_dim_64; num_layers_4; sentence_representation_average ----------\n",
      "Epoch 8: 100%|██████████| 5/5 [00:40<00:00,  0.12it/s, v_num=0, train_loss=0.671, train_acc=0.594, val_loss=0.722, val_acc=0.536]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 14:36:19,557] Trial 2 finished with value: 0.692599356174469 and parameters: {'hidden_dim': 64, 'num_layers': 4, 'optimizer_name': 'Adagrad', 'batch_size': 2048, 'learning_rate': 0.1, 'sentence_representation_type': 'average'}. Best is trial 1 with value: 0.7769343256950378.\n",
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type               | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model  | RNN                | 5.0 M  | train\n",
      "1 | metric | MulticlassAccuracy | 0      | train\n",
      "------------------------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "19.951    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- batch_size_2048; lr_0.1; optimizer_Adam; hidden_dim_32; num_layers_1; sentence_representation_max ----------\n",
      "Epoch 4: 100%|██████████| 5/5 [00:32<00:00,  0.15it/s, v_num=0, train_loss=0.238, train_acc=0.896, val_loss=0.946, val_acc=0.678]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 14:39:27,312] Trial 3 finished with value: 0.7135953903198242 and parameters: {'hidden_dim': 32, 'num_layers': 1, 'optimizer_name': 'Adam', 'batch_size': 2048, 'learning_rate': 0.1, 'sentence_representation_type': 'max'}. Best is trial 1 with value: 0.7769343256950378.\n",
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type               | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model  | RNN                | 6.2 M  | train\n",
      "1 | metric | MulticlassAccuracy | 0      | train\n",
      "------------------------------------------------------\n",
      "6.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.2 M     Total params\n",
      "24.657    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- batch_size_2048; lr_0.001; optimizer_Adam; hidden_dim_128; num_layers_3; sentence_representation_average ----------\n",
      "Epoch 8: 100%|██████████| 5/5 [00:44<00:00,  0.11it/s, v_num=0, train_loss=0.203, train_acc=0.936, val_loss=0.619, val_acc=0.762]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 14:47:02,889] Trial 4 finished with value: 0.5447974801063538 and parameters: {'hidden_dim': 128, 'num_layers': 3, 'optimizer_name': 'Adam', 'batch_size': 2048, 'learning_rate': 0.001, 'sentence_representation_type': 'average'}. Best is trial 1 with value: 0.7769343256950378.\n",
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type               | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model  | RNN                | 5.0 M  | train\n",
      "1 | metric | MulticlassAccuracy | 0      | train\n",
      "------------------------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "20.052    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- batch_size_2048; lr_0.001; optimizer_Adagrad; hidden_dim_32; num_layers_2; sentence_representation_last ----------\n",
      "Epoch 18: 100%|██████████| 5/5 [00:33<00:00,  0.15it/s, v_num=0, train_loss=0.307, train_acc=0.907, val_loss=0.549, val_acc=0.750]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 14:58:00,079] Trial 5 finished with value: 0.5336838960647583 and parameters: {'hidden_dim': 32, 'num_layers': 2, 'optimizer_name': 'Adagrad', 'batch_size': 2048, 'learning_rate': 0.001, 'sentence_representation_type': 'last'}. Best is trial 1 with value: 0.7769343256950378.\n",
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type               | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model  | RNN                | 5.2 M  | train\n",
      "1 | metric | MulticlassAccuracy | 0      | train\n",
      "------------------------------------------------------\n",
      "5.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.2 M     Total params\n",
      "20.781    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- batch_size_2048; lr_0.01; optimizer_Adagrad; hidden_dim_64; num_layers_2; sentence_representation_last ----------\n",
      "Epoch 5: 100%|██████████| 5/5 [00:35<00:00,  0.14it/s, v_num=0, train_loss=0.195, train_acc=0.917, val_loss=0.622, val_acc=0.759]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 15:01:59,968] Trial 6 finished with value: 0.5453187823295593 and parameters: {'hidden_dim': 64, 'num_layers': 2, 'optimizer_name': 'Adagrad', 'batch_size': 2048, 'learning_rate': 0.01, 'sentence_representation_type': 'last'}. Best is trial 1 with value: 0.7769343256950378.\n",
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type               | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model  | RNN                | 5.1 M  | train\n",
      "1 | metric | MulticlassAccuracy | 0      | train\n",
      "------------------------------------------------------\n",
      "5.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 M     Total params\n",
      "20.252    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- batch_size_2048; lr_0.0001; optimizer_Adam; hidden_dim_32; num_layers_4; sentence_representation_average ----------\n",
      "Epoch 45: 100%|██████████| 5/5 [00:36<00:00,  0.14it/s, v_num=0, train_loss=0.460, train_acc=0.866, val_loss=0.606, val_acc=0.726]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 15:30:40,119] Trial 7 finished with value: 0.6018025875091553 and parameters: {'hidden_dim': 32, 'num_layers': 4, 'optimizer_name': 'Adam', 'batch_size': 2048, 'learning_rate': 0.0001, 'sentence_representation_type': 'average'}. Best is trial 1 with value: 0.7769343256950378.\n",
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type               | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model  | RNN                | 6.2 M  | train\n",
      "1 | metric | MulticlassAccuracy | 0      | train\n",
      "------------------------------------------------------\n",
      "6.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.2 M     Total params\n",
      "24.699    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- batch_size_2048; lr_0.01; optimizer_Adagrad; hidden_dim_256; num_layers_1; sentence_representation_last ----------\n",
      "Epoch 8: 100%|██████████| 5/5 [00:41<00:00,  0.12it/s, v_num=0, train_loss=0.147, train_acc=0.924, val_loss=0.694, val_acc=0.738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 15:37:21,499] Trial 8 finished with value: 0.5881122946739197 and parameters: {'hidden_dim': 256, 'num_layers': 1, 'optimizer_name': 'Adagrad', 'batch_size': 2048, 'learning_rate': 0.01, 'sentence_representation_type': 'last'}. Best is trial 1 with value: 0.7769343256950378.\n",
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type               | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model  | RNN                | 9.3 M  | train\n",
      "1 | metric | MulticlassAccuracy | 0      | train\n",
      "------------------------------------------------------\n",
      "9.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.3 M     Total params\n",
      "37.315    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- batch_size_2048; lr_0.01; optimizer_Adagrad; hidden_dim_256; num_layers_3; sentence_representation_max ----------\n",
      "Epoch 5: 100%|██████████| 5/5 [01:07<00:00,  0.07it/s, v_num=0, train_loss=0.693, train_acc=0.500, val_loss=0.693, val_acc=0.500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-08 15:44:44,911] Trial 9 finished with value: 0.6928321123123169 and parameters: {'hidden_dim': 256, 'num_layers': 3, 'optimizer_name': 'Adagrad', 'batch_size': 2048, 'learning_rate': 0.01, 'sentence_representation_type': 'max'}. Best is trial 1 with value: 0.7769343256950378.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from utils.train import train_rnn_model_with_parameters\n",
    "\n",
    "SEARCH_SPACE = {\n",
    "    \"batch_size\": [2048],\n",
    "    \"learning_rate\": [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    \"optimizer_name\": [\"Adam\", \"Adagrad\",],\n",
    "    # RNN Model Parameters\n",
    "    \"hidden_dim\": [256, 128, 64, 32],\n",
    "    \"num_layers\": [1, 2, 4],\n",
    "    \"sentence_representation_type\": [\"last\", \"average\", \"max\"],\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", SEARCH_SPACE[\"hidden_dim\"])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", min(SEARCH_SPACE[\"num_layers\"]), max(SEARCH_SPACE[\"num_layers\"]))\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer_name\", SEARCH_SPACE[\"optimizer_name\"])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", SEARCH_SPACE[\"batch_size\"])\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", SEARCH_SPACE[\"learning_rate\"])\n",
    "    sentence_representation_type = trial.suggest_categorical(\"sentence_representation_type\", SEARCH_SPACE[\"sentence_representation_type\"])\n",
    "    \n",
    "    log_message = f\"---------- batch_size_{batch_size}; lr_{learning_rate}; optimizer_{optimizer_name}; hidden_dim_{hidden_dim}; num_layers_{num_layers}; sentence_representation_{sentence_representation_type} ----------\"\n",
    "    print(log_message)\n",
    "\n",
    "    val_acc = train_rnn_model_with_parameters(\n",
    "        embedding_matrix=embedding_matrix,\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        optimizer_name=optimizer_name,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        sentence_representation_type=sentence_representation_type,\n",
    "        show_progress=True,\n",
    "        log_dir=\"biLSTM-oov/test\",\n",
    "        rnn_type=\"LSTM\",\n",
    "        bidirectional=True,\n",
    "        freeze_embedding=False\n",
    "    )\n",
    "    \n",
    "    return val_acc\n",
    "\n",
    "# Set up the Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\") \n",
    "study.optimize(objective, n_trials=10) \n",
    "\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_dim': 256,\n",
       " 'num_layers': 2,\n",
       " 'optimizer_name': 'Adagrad',\n",
       " 'batch_size': 2048,\n",
       " 'learning_rate': 0.1,\n",
       " 'sentence_representation_type': 'last'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configurations Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "DATA in match_rnn_log\n",
      "Results for biLSTM with OOV method\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_acc</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer_name</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>sentence_representation_type</th>\n",
       "      <th>freeze</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.791745</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.092932</td>\n",
       "      <td>0.961358</td>\n",
       "      <td>1</td>\n",
       "      <td>average</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.524783</td>\n",
       "      <td>events.out.tfevents.1731018611.Bernices-MacBoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786116</td>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.117063</td>\n",
       "      <td>0.967680</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.486323</td>\n",
       "      <td>events.out.tfevents.1731013380.Bernices-MacBoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.779550</td>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.316925</td>\n",
       "      <td>0.881039</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>False</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.487491</td>\n",
       "      <td>events.out.tfevents.1731017839.Bernices-MacBoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.778612</td>\n",
       "      <td>2048</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.298538</td>\n",
       "      <td>0.867635</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>False</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.489787</td>\n",
       "      <td>events.out.tfevents.1730998423.Bernices-MacBoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.773921</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.241678</td>\n",
       "      <td>0.920623</td>\n",
       "      <td>3</td>\n",
       "      <td>max</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.517354</td>\n",
       "      <td>events.out.tfevents.1730990217.Bernices-MacBoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.772983</td>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.100994</td>\n",
       "      <td>0.966198</td>\n",
       "      <td>1</td>\n",
       "      <td>last</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.519525</td>\n",
       "      <td>events.out.tfevents.1730994098.Bernices-MacBoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.772045</td>\n",
       "      <td>2048</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.936922</td>\n",
       "      <td>2</td>\n",
       "      <td>average</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.558855</td>\n",
       "      <td>events.out.tfevents.1730993100.Bernices-MacBoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>2048</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.212386</td>\n",
       "      <td>0.942633</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>False</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.476411</td>\n",
       "      <td>events.out.tfevents.1730994491.Bernices-MacBoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.768293</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.219571</td>\n",
       "      <td>0.932048</td>\n",
       "      <td>4</td>\n",
       "      <td>max</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.525361</td>\n",
       "      <td>events.out.tfevents.1730992028.Bernices-MacBoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.765478</td>\n",
       "      <td>2048</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.174375</td>\n",
       "      <td>0.931984</td>\n",
       "      <td>2</td>\n",
       "      <td>last</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.562326</td>\n",
       "      <td>events.out.tfevents.1731008580.Bernices-MacBoo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    val_acc  batch_size  hidden_dim  learning_rate optimizer_name  train_loss  \\\n",
       "0  0.791745        2048         128         0.0100        Adagrad    0.092932   \n",
       "1  0.786116        2048          64         0.0010           Adam    0.117063   \n",
       "2  0.779550        2048          64         0.0010        Adagrad    0.316925   \n",
       "3  0.778612        2048         256         0.0010        Adagrad    0.298538   \n",
       "4  0.773921        2048         128         0.0100        Adagrad    0.241678   \n",
       "5  0.772983        2048          64         0.0010           Adam    0.100994   \n",
       "6  0.772045        2048          32         0.0100        Adagrad    0.205683   \n",
       "7  0.769231        2048          32         0.0001           Adam    0.212386   \n",
       "8  0.768293        2048         128         0.0100        Adagrad    0.219571   \n",
       "9  0.765478        2048          32         0.0010           Adam    0.174375   \n",
       "\n",
       "   train_acc  num_layers sentence_representation_type  freeze  epoch  \\\n",
       "0   0.961358           1                      average   False    8.0   \n",
       "1   0.967680           1                          max   False   10.0   \n",
       "2   0.881039           1                          max   False   21.0   \n",
       "3   0.867635           1                          max   False   14.0   \n",
       "4   0.920623           3                          max   False    6.0   \n",
       "5   0.966198           1                         last   False   10.0   \n",
       "6   0.936922           2                      average   False    6.0   \n",
       "7   0.942633           1                          max   False   59.0   \n",
       "8   0.932048           4                          max   False    6.0   \n",
       "9   0.931984           2                         last   False    8.0   \n",
       "\n",
       "   val_loss                                           filename  \n",
       "0  0.524783  events.out.tfevents.1731018611.Bernices-MacBoo...  \n",
       "1  0.486323  events.out.tfevents.1731013380.Bernices-MacBoo...  \n",
       "2  0.487491  events.out.tfevents.1731017839.Bernices-MacBoo...  \n",
       "3  0.489787  events.out.tfevents.1730998423.Bernices-MacBoo...  \n",
       "4  0.517354  events.out.tfevents.1730990217.Bernices-MacBoo...  \n",
       "5  0.519525  events.out.tfevents.1730994098.Bernices-MacBoo...  \n",
       "6  0.558855  events.out.tfevents.1730993100.Bernices-MacBoo...  \n",
       "7  0.476411  events.out.tfevents.1730994491.Bernices-MacBoo...  \n",
       "8  0.525361  events.out.tfevents.1730992028.Bernices-MacBoo...  \n",
       "9  0.562326  events.out.tfevents.1731008580.Bernices-MacBoo...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.analytics import load_tensorboard_logs\n",
    "\n",
    "train_results_df = load_tensorboard_logs(log_dir=\"tb_logs/bilstm-oov\")\n",
    "train_results_df = train_results_df.sort_values(\n",
    "    by=[\"val_acc\"], ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"Results for biLSTM with OOV method\")\n",
    "train_results_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a) Final Configuration of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RNN model (with OOV)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_acc</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer_name</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>sentence_representation_type</th>\n",
       "      <th>freeze</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.791745</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.092932</td>\n",
       "      <td>0.961358</td>\n",
       "      <td>1</td>\n",
       "      <td>average</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.524783</td>\n",
       "      <td>events.out.tfevents.1731018611.Bernices-MacBoo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    val_acc  batch_size  hidden_dim  learning_rate optimizer_name  train_loss  \\\n",
       "0  0.791745        2048         128           0.01        Adagrad    0.092932   \n",
       "\n",
       "   train_acc  num_layers sentence_representation_type  freeze  epoch  \\\n",
       "0   0.961358           1                      average   False    8.0   \n",
       "\n",
       "   val_loss                                           filename  \n",
       "0  0.524783  events.out.tfevents.1731018611.Bernices-MacBoo...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rnn_model_configuration = train_results_df.head(1)\n",
    "\n",
    "print(\"Best RNN model (with OOV)\")\n",
    "best_rnn_model_configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best checkpoint:  tb_logs/biLSTM-oov/test/batch_size_2048-lr_0.01-optimizer_Adagrad-hidden_dim_128-num_layers_1-sr_type_average-freeze_False-rnn_type_LSTM-bidirectional_True/version_0/checkpoints/epoch=5-step=30.ckpt\n",
      "RNNClassifier(\n",
      "  (model): RNN(\n",
      "    (embedding): Embedding(16334, 300)\n",
      "    (rnn): LSTM(300, 128, batch_first=True, bidirectional=True)\n",
      "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      "  (metric): MulticlassAccuracy()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bern/anaconda3/envs/nlp_project_new/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'rnn_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['rnn_model'])`.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from models.RNN import RNNClassifier\n",
    "\n",
    "best_rnn_model_filename = best_rnn_model_configuration[\"filename\"].item()\n",
    "matched_files = list(Path().rglob(best_rnn_model_filename))\n",
    "\n",
    "if not matched_files:\n",
    "    print(\"Model checkpoint not found!\")\n",
    "else:\n",
    "    checkpoint_dir = matched_files[0].parent / \"checkpoints\"\n",
    "    checkpoint_files = (\n",
    "        list(checkpoint_dir.glob(\"*.ckpt\")) if checkpoint_dir.exists() else []\n",
    "    )\n",
    "\n",
    "    if not checkpoint_files:\n",
    "        print(\"No checkpoint files found in the checkpoint directory!\")\n",
    "    else:\n",
    "        best_checkpoint = checkpoint_files[0] \n",
    "        print(\"best checkpoint: \", best_checkpoint)\n",
    "        best_rnn_model = RNNClassifier.load_from_checkpoint(best_checkpoint)\n",
    "        print(best_rnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b) Accuracy on Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bern/anaconda3/envs/nlp_project_new/lib/python3.11/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/bern/anaconda3/envs/nlp_project_new/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:475: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/Users/bern/anaconda3/envs/nlp_project_new/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1066/1066 [00:02<00:00, 360.58it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.7833020687103271\n",
      "        test_loss           0.6383655071258545\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.6383655071258545, 'test_acc': 0.7833020687103271}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightning as L\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True)\n",
    "\n",
    "trainer = L.Trainer(accelerator=\"cpu\")\n",
    "trainer.test(best_rnn_model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
