{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Model Training & Evaluation - biLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare embedding matrix and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "embedding_path = Path(\"models/embedding_matrix_oov.npy\")\n",
    "index_from_word_path = Path(\"models/index_from_word_oov.json\")\n",
    "\n",
    "embedding_matrix = np.load(embedding_path)\n",
    "with index_from_word_path.open() as f:\n",
    "    index_from_word = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text import tokenize\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = tokenize(dataset[\"train\"])\n",
    "val_dataset = tokenize(dataset[\"validation\"])\n",
    "test_dataset = tokenize(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text import token_to_index\n",
    "\n",
    "train_dataset = token_to_index(dataset=train_dataset, index_from_word=index_from_word)\n",
    "val_dataset = token_to_index(dataset=val_dataset, index_from_word=index_from_word)\n",
    "test_dataset = token_to_index(dataset=test_dataset, index_from_word=index_from_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])\n",
    "val_dataset = val_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])\n",
    "test_dataset = test_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(type=\"torch\")\n",
    "val_dataset.set_format(type=\"torch\")\n",
    "test_dataset.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'original_len', 'indexes'],\n",
       "    num_rows: 8530\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RNN - biLSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieuristic search with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from utils.train import train_rnn_model_with_parameters\n",
    "\n",
    "_N_TRIALS = 150\n",
    "SEARCH_SPACE = {\n",
    "    \"batch_size\": [2048],\n",
    "    \"learning_rate\": [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    \"optimizer_name\": [\"Adam\", \"Adagrad\",],\n",
    "    # biLSTM Model Parameters\n",
    "    \"hidden_dim\": [256, 128, 64, 32],\n",
    "    \"num_layers\": [1, 2, 4],\n",
    "    \"sentence_representation_type\": [\"last\", \"average\", \"max\"],\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", SEARCH_SPACE[\"hidden_dim\"])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", min(SEARCH_SPACE[\"num_layers\"]), max(SEARCH_SPACE[\"num_layers\"]))\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer_name\", SEARCH_SPACE[\"optimizer_name\"])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", SEARCH_SPACE[\"batch_size\"])\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", SEARCH_SPACE[\"learning_rate\"])\n",
    "    sentence_representation_type = trial.suggest_categorical(\"sentence_representation_type\", SEARCH_SPACE[\"sentence_representation_type\"])\n",
    "    \n",
    "    log_message = f\"---------- batch_size_{batch_size}; lr_{learning_rate}; optimizer_{optimizer_name}; hidden_dim_{hidden_dim}; num_layers_{num_layers}; sentence_representation_{sentence_representation_type} ----------\"\n",
    "    print(log_message)\n",
    "\n",
    "    val_acc = train_rnn_model_with_parameters(\n",
    "        embedding_matrix=embedding_matrix,\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        optimizer_name=optimizer_name,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        sentence_representation_type=sentence_representation_type,\n",
    "        show_progress=True,\n",
    "        log_dir=\"bilstm\",\n",
    "        rnn_type=\"LSTM\",\n",
    "        bidirectional=True,\n",
    "        freeze_embedding=False\n",
    "    )\n",
    "    \n",
    "    return val_acc\n",
    "\n",
    "# Set up the Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\") \n",
    "study.optimize(objective, n_trials=_N_TRIALS)\n",
    "\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analytics import load_tensorboard_logs\n",
    "\n",
    "train_results_df = load_tensorboard_logs(log_dir=\"tb_logs/bilstm\")\n",
    "train_results_df = train_results_df.sort_values(\n",
    "    by=[\"val_acc\"], ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "train_results_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rnn_model_configuration = train_results_df.head(1)\n",
    "best_rnn_model_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analytics import test_top_n_models\n",
    "from models.RNN import RNNClassifier\n",
    "\n",
    "test_results_df = test_top_n_models(train_results_df, RNNClassifier, test_dataset, n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
