{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3(a)\n",
    "\n",
    "This notebook will highlight the process, result and insights obtained from allowing updates to the embedding matrix during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "embedding_path = Path(\"models/embedding_matrix.npy\")\n",
    "index_from_word_path = Path(\"models/index_from_word.json\")\n",
    "\n",
    "embedding_matrix = np.load(embedding_path)\n",
    "with index_from_word_path.open() as f:\n",
    "    index_from_word = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataaset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\juinl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\juinl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\juinl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils.text import tokenize\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = tokenize(dataset[\"train\"])\n",
    "val_dataset = tokenize(dataset[\"validation\"])\n",
    "test_dataset = tokenize(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Tokenise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'tokens', 'original_len', 'indexes'],\n",
       "    num_rows: 8530\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.text import token_to_index\n",
    "\n",
    "train_dataset = token_to_index(dataset=train_dataset, index_from_word=index_from_word)\n",
    "val_dataset = token_to_index(dataset=val_dataset, index_from_word=index_from_word)\n",
    "test_dataset = token_to_index(dataset=test_dataset, index_from_word=index_from_word)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])\n",
    "val_dataset = val_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])\n",
    "test_dataset = test_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(type=\"torch\")\n",
    "val_dataset.set_format(type=\"torch\")\n",
    "test_dataset.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Optuna to perform heuristic search on optimal configuration when embeddings are updatable during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from utils.train import train_rnn_model_with_parameters\n",
    "\n",
    "SEARCH_SPACE = {\n",
    "    \"batch_size\": [32, 64, 128, 256, 512, 1024, 2048],\n",
    "    \"learning_rate\": [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    \"optimizer_name\": [\"Adam\", \"Adagrad\", \"RMSprop\"],\n",
    "    # RNN Model Parameters\n",
    "    \"hidden_dim\": [256, 128, 64, 32],\n",
    "    \"num_layers\": [1, 2, 4],\n",
    "    \"sentence_representation_type\": [\"last\", \"average\", \"max\"],\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", SEARCH_SPACE[\"hidden_dim\"])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", min(SEARCH_SPACE[\"num_layers\"]), max(SEARCH_SPACE[\"num_layers\"]))\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer_name\", SEARCH_SPACE[\"optimizer_name\"])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", SEARCH_SPACE[\"batch_size\"])\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", SEARCH_SPACE[\"learning_rate\"])\n",
    "    sentence_representation_type = trial.suggest_categorical(\"sentence_representation_type\", SEARCH_SPACE[\"sentence_representation_type\"])\n",
    "    \n",
    "    log_message = f\"---------- batch_size_{batch_size}; lr_{learning_rate}; optimizer_{optimizer_name}; hidden_dim_{hidden_dim}; num_layers_{num_layers}; sentence_representation_{sentence_representation_type} ----------\"\n",
    "    print(log_message)\n",
    "\n",
    "    val_acc = train_rnn_model_with_parameters(\n",
    "        embedding_matrix=embedding_matrix,\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        optimizer_name=optimizer_name,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        sentence_representation_type=sentence_representation_type,\n",
    "        show_progress=False,\n",
    "        freeze_embedding=False,\n",
    "        log_dir=\"rnn/test/w2v-3a\"\n",
    "    )\n",
    "    \n",
    "    return val_acc\n",
    "\n",
    "# Set up the Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=150)  \n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Load result from all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>freeze</th>\n",
       "      <th>optimizer_name</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>sentence_representation_type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.779550</td>\n",
       "      <td>0.890533</td>\n",
       "      <td>2048</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.434699</td>\n",
       "      <td>0.510937</td>\n",
       "      <td>events.out.tfevents.1730624293.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.776735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2048</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>False</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>2</td>\n",
       "      <td>max</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.490966</td>\n",
       "      <td>events.out.tfevents.1730640444.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.775797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.487259</td>\n",
       "      <td>events.out.tfevents.1730639894.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.772983</td>\n",
       "      <td>0.893217</td>\n",
       "      <td>2048</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.405118</td>\n",
       "      <td>0.525215</td>\n",
       "      <td>events.out.tfevents.1730627220.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.772983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>max</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522750</td>\n",
       "      <td>events.out.tfevents.1730639566.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.772045</td>\n",
       "      <td>0.946746</td>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.186989</td>\n",
       "      <td>0.488326</td>\n",
       "      <td>events.out.tfevents.1730624617.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.772045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.498227</td>\n",
       "      <td>events.out.tfevents.1730625631.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.772045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2048</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.487313</td>\n",
       "      <td>events.out.tfevents.1730626954.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.771107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>last</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501685</td>\n",
       "      <td>events.out.tfevents.1730624983.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.872268</td>\n",
       "      <td>2048</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>max</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.410194</td>\n",
       "      <td>0.510118</td>\n",
       "      <td>events.out.tfevents.1730623825.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.766417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2048</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>max</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504346</td>\n",
       "      <td>events.out.tfevents.1730622672.LEEJUIN-PC.23360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.766417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>max</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.526397</td>\n",
       "      <td>events.out.tfevents.1730627739.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.766417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.479756</td>\n",
       "      <td>events.out.tfevents.1730627410.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.765478</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>max</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.184201</td>\n",
       "      <td>0.492373</td>\n",
       "      <td>events.out.tfevents.1730639630.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.764540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>last</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527429</td>\n",
       "      <td>events.out.tfevents.1730626115.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.764396</td>\n",
       "      <td>0.928585</td>\n",
       "      <td>1024</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>2</td>\n",
       "      <td>max</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.216643</td>\n",
       "      <td>0.485398</td>\n",
       "      <td>events.out.tfevents.1730640845.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.764300</td>\n",
       "      <td>0.941192</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.182825</td>\n",
       "      <td>0.478799</td>\n",
       "      <td>events.out.tfevents.1730627593.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.762664</td>\n",
       "      <td>0.857313</td>\n",
       "      <td>2048</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>average</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.437008</td>\n",
       "      <td>0.545861</td>\n",
       "      <td>events.out.tfevents.1730625562.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.761726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2048</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>max</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533986</td>\n",
       "      <td>events.out.tfevents.1730639497.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.760788</td>\n",
       "      <td>0.863905</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>last</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.362671</td>\n",
       "      <td>0.517812</td>\n",
       "      <td>events.out.tfevents.1730623580.LEEJUIN-PC.23360.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     val_acc  train_acc  batch_size  hidden_dim  learning_rate  freeze  \\\n",
       "0   0.779550   0.890533        2048          32         0.0010   False   \n",
       "1   0.776735        NaN        2048          32         0.0100   False   \n",
       "2   0.775797        NaN        2048         128         0.0010   False   \n",
       "3   0.772983   0.893217        2048          32         0.0001   False   \n",
       "4   0.772983        NaN        2048          64         0.0100   False   \n",
       "5   0.772045   0.946746        2048          64         0.0010   False   \n",
       "6   0.772045        NaN        2048          64         0.0100   False   \n",
       "7   0.772045        NaN        2048         256         0.0010   False   \n",
       "8   0.771107        NaN        2048         128         0.0010   False   \n",
       "9   0.768293   0.872268        2048          32         0.0010   False   \n",
       "10  0.766417        NaN        2048         256         0.0010   False   \n",
       "11  0.766417        NaN        2048         128         0.0010   False   \n",
       "12  0.766417        NaN        2048         128         0.0010   False   \n",
       "13  0.765478   0.939560        2048          64         0.0010   False   \n",
       "14  0.764540        NaN        2048          64         0.0010   False   \n",
       "15  0.764396   0.928585        1024          32         0.0010   False   \n",
       "16  0.764300   0.941192        1024         256         0.0010   False   \n",
       "17  0.762664   0.857313        2048          32         0.0010   False   \n",
       "18  0.761726        NaN        2048          32         0.0100   False   \n",
       "19  0.760788   0.863905        2048         128         0.0001   False   \n",
       "\n",
       "   optimizer_name  num_layers sentence_representation_type  epoch  train_loss  \\\n",
       "0            Adam           1                          max   15.0    0.434699   \n",
       "1         Adagrad           2                          max    8.0         NaN   \n",
       "2         RMSprop           1                          max    7.0         NaN   \n",
       "3            Adam           1                          max   74.0    0.405118   \n",
       "4            Adam           2                          max    5.0         NaN   \n",
       "5            Adam           1                          max   10.0    0.186989   \n",
       "6            Adam           1                          max    4.0         NaN   \n",
       "7            Adam           1                          max    7.0         NaN   \n",
       "8            Adam           1                         last    7.0         NaN   \n",
       "9            Adam           2                          max   13.0    0.410194   \n",
       "10           Adam           2                          max    6.0         NaN   \n",
       "11           Adam           4                          max    7.0         NaN   \n",
       "12           Adam           1                          max    8.0         NaN   \n",
       "13           Adam           2                          max    9.0    0.184201   \n",
       "14           Adam           1                         last    8.0         NaN   \n",
       "15        RMSprop           2                          max    7.0    0.216643   \n",
       "16           Adam           1                          max    5.0    0.182825   \n",
       "17           Adam           2                      average   14.0    0.437008   \n",
       "18           Adam           2                          max    6.0         NaN   \n",
       "19           Adam           2                         last   23.0    0.362671   \n",
       "\n",
       "    val_loss                                           filename  \n",
       "0   0.510937  events.out.tfevents.1730624293.LEEJUIN-PC.2336...  \n",
       "1   0.490966  events.out.tfevents.1730640444.LEEJUIN-PC.2336...  \n",
       "2   0.487259  events.out.tfevents.1730639894.LEEJUIN-PC.2336...  \n",
       "3   0.525215  events.out.tfevents.1730627220.LEEJUIN-PC.2336...  \n",
       "4   0.522750  events.out.tfevents.1730639566.LEEJUIN-PC.2336...  \n",
       "5   0.488326  events.out.tfevents.1730624617.LEEJUIN-PC.2336...  \n",
       "6   0.498227  events.out.tfevents.1730625631.LEEJUIN-PC.2336...  \n",
       "7   0.487313  events.out.tfevents.1730626954.LEEJUIN-PC.2336...  \n",
       "8   0.501685  events.out.tfevents.1730624983.LEEJUIN-PC.2336...  \n",
       "9   0.510118  events.out.tfevents.1730623825.LEEJUIN-PC.2336...  \n",
       "10  0.504346  events.out.tfevents.1730622672.LEEJUIN-PC.23360.0  \n",
       "11  0.526397  events.out.tfevents.1730627739.LEEJUIN-PC.2336...  \n",
       "12  0.479756  events.out.tfevents.1730627410.LEEJUIN-PC.2336...  \n",
       "13  0.492373  events.out.tfevents.1730639630.LEEJUIN-PC.2336...  \n",
       "14  0.527429  events.out.tfevents.1730626115.LEEJUIN-PC.2336...  \n",
       "15  0.485398  events.out.tfevents.1730640845.LEEJUIN-PC.2336...  \n",
       "16  0.478799  events.out.tfevents.1730627593.LEEJUIN-PC.2336...  \n",
       "17  0.545861  events.out.tfevents.1730625562.LEEJUIN-PC.2336...  \n",
       "18  0.533986  events.out.tfevents.1730639497.LEEJUIN-PC.2336...  \n",
       "19  0.517812  events.out.tfevents.1730623580.LEEJUIN-PC.23360.9  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.analytics import load_tensorboard_logs\n",
    "\n",
    "train_results_df = load_tensorboard_logs(log_dir=\"tb_logs/rnn/test/w2v-3a\")\n",
    "\n",
    "train_results_df = train_results_df.sort_values(\n",
    "    by=[\"val_acc\"], ascending=False\n",
    ").reset_index(drop=True)\n",
    "train_results_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Configuration for best trial result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>freeze</th>\n",
       "      <th>optimizer_name</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>sentence_representation_type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.77955</td>\n",
       "      <td>0.890533</td>\n",
       "      <td>2048</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>max</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.434699</td>\n",
       "      <td>0.510937</td>\n",
       "      <td>events.out.tfevents.1730624293.LEEJUIN-PC.2336...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_acc  train_acc  batch_size  hidden_dim  learning_rate  freeze  \\\n",
       "0  0.77955   0.890533        2048          32          0.001   False   \n",
       "\n",
       "  optimizer_name  num_layers sentence_representation_type  epoch  train_loss  \\\n",
       "0           Adam           1                          max   15.0    0.434699   \n",
       "\n",
       "   val_loss                                           filename  \n",
       "0  0.510937  events.out.tfevents.1730624293.LEEJUIN-PC.2336...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rnn_model_configuration = train_results_df.head(1)\n",
    "best_rnn_model_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Rerun best config trial to save the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "c:\\Users\\juinl\\Documents\\GitHub\\sc4002-nlp-sentiment-classification\\venv\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'rnn_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['rnn_model'])`.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\juinl\\Documents\\GitHub\\sc4002-nlp-sentiment-classification\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name   | Type               | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model  | RNN                | 4.5 M  | train\n",
      "1 | metric | MulticlassAccuracy | 0      | train\n",
      "------------------------------------------------------\n",
      "4.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.5 M     Total params\n",
      "17.911    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b24b10a2f24af5a5dd0f3c0cfba4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juinl\\Documents\\GitHub\\sc4002-nlp-sentiment-classification\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\juinl\\Documents\\GitHub\\sc4002-nlp-sentiment-classification\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\juinl\\Documents\\GitHub\\sc4002-nlp-sentiment-classification\\venv\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0bbb528e42440ca5b91995ca56d700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da4dad8ba5745279866220393f76e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716a270dfd724814b8313d020b0e019e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a07e5d44144900bd03d9c305c2b5ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22018f8e59e946eeb023f99f1540fe4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43d9008de5540ec8ef5b52d609a91a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5849458c760543c3b230a5c217110571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7024249eddc74e53b79866ebe794dbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ad9f391cf249f3b76ae6c551a2d9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b15783075d457bbcbdfc94d11c1e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ff079d37b04882956c322dd3af7ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d606445c56dd426da05af9e3dc40088a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57fcd7c394c4be6a41304972cbf7910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5954b00e377e4b2a8968f8395d419862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5b2e9fdd884886bbfef51501607514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a471a0344d754e13a7db7ff4e63e52a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5a5c501f5f4147abd391acd34a9868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7795497179031372"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.train import train_rnn_model_with_parameters\n",
    "\n",
    "train_rnn_model_with_parameters(\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=2048,\n",
    "    learning_rate=0.001,\n",
    "    optimizer_name=\"Adam\",\n",
    "    hidden_dim=32,\n",
    "    num_layers=1,\n",
    "    sentence_representation_type=\"max\",\n",
    "    show_progress=False,\n",
    "    freeze_embedding=False,\n",
    "    write_embeddings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Load updated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "embedding_path = Path(\"models/test.npy\")\n",
    "updated_embedding_matrix = np.load(embedding_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Model with best trial configuration and updated embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.RNN import RNN\n",
    "\n",
    "rnn_model = RNN(\n",
    "    embedding_matrix=updated_embedding_matrix,\n",
    "    hidden_dim=32,\n",
    "    output_dim=2,\n",
    "    num_layers=1,\n",
    "    sentence_representation_type=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNClassifier(\n",
      "  (model): RNN(\n",
      "    (embedding): Embedding(14888, 300)\n",
      "    (rnn): RNN(300, 32, batch_first=True)\n",
      "    (fc): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (fc2): Linear(in_features=16, out_features=2, bias=True)\n",
      "  )\n",
      "  (metric): MulticlassAccuracy()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from utils.train import RNNClassifier\n",
    "\n",
    "\n",
    "best_rnn_model_filename = best_rnn_model_configuration[\"filename\"].item()\n",
    "matched_files = list(Path().rglob(best_rnn_model_filename))\n",
    "\n",
    "if not matched_files:\n",
    "    print(\"Model checkpoint not found!\")\n",
    "else:\n",
    "    checkpoint_dir = matched_files[0].parent / \"checkpoints\"\n",
    "    checkpoint_files = (\n",
    "        list(checkpoint_dir.glob(\"*.ckpt\")) if checkpoint_dir.exists() else []\n",
    "    )\n",
    "\n",
    "    if not checkpoint_files:\n",
    "        print(\"No checkpoint files found in the checkpoint directory!\")\n",
    "    else:\n",
    "        best_checkpoint = checkpoint_files[0] \n",
    "        best_rnn_model = RNNClassifier.load_from_checkpoint(\n",
    "            best_checkpoint, rnn_model=rnn_model\n",
    "        )\n",
    "        print(best_rnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Accuracy test on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\juinl\\Documents\\GitHub\\sc4002-nlp-sentiment-classification\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "c:\\Users\\juinl\\Documents\\GitHub\\sc4002-nlp-sentiment-classification\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:475: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "c:\\Users\\juinl\\Documents\\GitHub\\sc4002-nlp-sentiment-classification\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32603de629945d28d4a6021726a1804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.7786116600036621\n",
      "        test_loss           0.4890058934688568\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.4890058934688568, 'test_acc': 0.7786116600036621}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightning as L\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True)\n",
    "\n",
    "trainer = L.Trainer(accelerator=\"cpu\")\n",
    "trainer.test(best_rnn_model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
