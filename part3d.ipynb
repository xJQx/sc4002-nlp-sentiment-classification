{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3.4. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare embedding matrix and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load the embedding matrix that handled OOV words\n",
    "embedding_path = Path(\"models/w2v_matrix.npy\")\n",
    "index_from_word_path = Path(\"models/w2v_index.json\")\n",
    "\n",
    "embedding_matrix = np.load(embedding_path)\n",
    "with index_from_word_path.open() as f:\n",
    "    index_from_word = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text import tokenize\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = tokenize(dataset[\"train\"])\n",
    "val_dataset = tokenize(dataset[\"validation\"])\n",
    "test_dataset = tokenize(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text import token_to_index\n",
    "\n",
    "train_dataset = token_to_index(dataset=train_dataset, index_from_word=index_from_word)\n",
    "val_dataset = token_to_index(dataset=val_dataset, index_from_word=index_from_word)\n",
    "test_dataset = token_to_index(dataset=test_dataset, index_from_word=index_from_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])\n",
    "val_dataset = val_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])\n",
    "test_dataset = test_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(type=\"torch\")\n",
    "val_dataset.set_format(type=\"torch\")\n",
    "test_dataset.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'original_len', 'indexes'],\n",
       "    num_rows: 8530\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_SPACE = {\n",
    "    \"batch_size\": [512, 1024, 2048],\n",
    "    \"learning_rate\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    \"optimizer_name\": [\"Adam\"],\n",
    "    # CNN Model Parameters\n",
    "    \"dropout\": [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    \"hidden_dim\": [600, 500, 400, 300],\n",
    "    \"n_grams\": [\n",
    "        [2],\n",
    "        [3],\n",
    "        [4],\n",
    "        [5],\n",
    "        [6],\n",
    "        [2, 3],\n",
    "        [2, 3, 4],\n",
    "        [2, 3, 4, 5],\n",
    "        [2, 3, 4, 6],\n",
    "        [3, 4],\n",
    "        [3, 4, 5],\n",
    "        [3, 4, 6],\n",
    "        [4, 5],\n",
    "        [4, 5, 6],\n",
    "        [5, 6],\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "from utils.train import (\n",
    "    CNNArgs,\n",
    "    DataArgs,\n",
    "    OptimizerArgs,\n",
    "    train_cnn_model_with_parameters,\n",
    ")\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", SEARCH_SPACE[\"batch_size\"])\n",
    "    learning_rate = trial.suggest_categorical(\n",
    "        \"learning_rate\", SEARCH_SPACE[\"learning_rate\"]\n",
    "    )\n",
    "    optimizer_name = trial.suggest_categorical(\n",
    "        \"optimizer_name\", SEARCH_SPACE[\"optimizer_name\"]\n",
    "    )\n",
    "    # CNN Model Parameters\n",
    "    dropout = trial.suggest_categorical(\"dropout\", SEARCH_SPACE[\"dropout\"])\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", SEARCH_SPACE[\"hidden_dim\"])\n",
    "    n_grams = trial.suggest_categorical(\"n_grams\", SEARCH_SPACE[\"n_grams\"])\n",
    "\n",
    "    log_message = f\"---------- batch_size_{batch_size}; lr_{learning_rate}; optimizer_{optimizer_name}; hidden_dim_{hidden_dim}; n_grams_{\"_\".join(map(str, n_grams))}; dropout_{dropout}  ----------\"\n",
    "    print(log_message)\n",
    "\n",
    "    cnn_args = CNNArgs(\n",
    "        embedding_matrix=embedding_matrix,\n",
    "        freeze_embedding=False,\n",
    "        hidden_dim=hidden_dim,\n",
    "        dropout=dropout,\n",
    "        n_grams=n_grams,\n",
    "    )\n",
    "\n",
    "    optimizer_args = OptimizerArgs(\n",
    "        optimizer_name=optimizer_name,\n",
    "        learning_rate=learning_rate,\n",
    "    )\n",
    "\n",
    "    data_args = DataArgs(\n",
    "        batch_size=batch_size,\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "    )\n",
    "\n",
    "    val_acc = train_cnn_model_with_parameters(\n",
    "        data_args=data_args,\n",
    "        cnn_args=cnn_args,\n",
    "        optimizer_args=optimizer_args,\n",
    "    )\n",
    "\n",
    "    return val_acc\n",
    "\n",
    "\n",
    "# Set up the Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer_name</th>\n",
       "      <th>n_grams</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.781426</td>\n",
       "      <td>0.930071</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.239519</td>\n",
       "      <td>0.481192</td>\n",
       "      <td>events.out.tfevents.1730676175.yuriarch.2971.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.778612</td>\n",
       "      <td>0.898188</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2_3_4_5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.301202</td>\n",
       "      <td>0.487332</td>\n",
       "      <td>events.out.tfevents.1730650766.yuriarch.53982.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.776735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.010</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.484529</td>\n",
       "      <td>events.out.tfevents.1730676650.yuriarch.2971.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.775797</td>\n",
       "      <td>0.822514</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.378091</td>\n",
       "      <td>0.482208</td>\n",
       "      <td>events.out.tfevents.1730675393.yuriarch.2971.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.773921</td>\n",
       "      <td>0.865978</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.321847</td>\n",
       "      <td>0.495995</td>\n",
       "      <td>events.out.tfevents.1730651270.yuriarch.53982.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.770169</td>\n",
       "      <td>0.875180</td>\n",
       "      <td>2048</td>\n",
       "      <td>400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2_3_4_5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.288041</td>\n",
       "      <td>0.478942</td>\n",
       "      <td>events.out.tfevents.1730651947.yuriarch.99853.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.770169</td>\n",
       "      <td>0.840097</td>\n",
       "      <td>2048</td>\n",
       "      <td>600</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.368825</td>\n",
       "      <td>0.488717</td>\n",
       "      <td>events.out.tfevents.1730675616.yuriarch.2971.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.944701</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3_4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.262486</td>\n",
       "      <td>0.491361</td>\n",
       "      <td>events.out.tfevents.1730649767.yuriarch.53982.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.988132</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.010</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2_3_4_6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.489992</td>\n",
       "      <td>events.out.tfevents.1730677377.yuriarch.2971.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.766417</td>\n",
       "      <td>0.878448</td>\n",
       "      <td>2048</td>\n",
       "      <td>300</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.415630</td>\n",
       "      <td>0.497469</td>\n",
       "      <td>events.out.tfevents.1730650200.yuriarch.53982.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     val_acc  train_acc  batch_size  hidden_dim  learning_rate optimizer_name  \\\n",
       "10  0.781426   0.930071        2048         500          0.001           Adam   \n",
       "23  0.778612   0.898188        2048         500          0.001           Adam   \n",
       "47  0.776735   1.000000        2048         500          0.010           Adam   \n",
       "2   0.775797   0.822514        2048         500          0.001           Adam   \n",
       "17  0.773921   0.865978        2048         500          0.001           Adam   \n",
       "13  0.770169   0.875180        2048         400          0.001           Adam   \n",
       "5   0.770169   0.840097        2048         600          0.001           Adam   \n",
       "43  0.769231   0.944701        2048         500          0.001           Adam   \n",
       "19  0.769231   0.988132        2048         500          0.010           Adam   \n",
       "14  0.766417   0.878448        2048         300          0.001           Adam   \n",
       "\n",
       "    n_grams dropout  epoch  train_loss  val_loss  \\\n",
       "10        2     0.3   13.0    0.239519  0.481192   \n",
       "23  2_3_4_5     0.7   28.0    0.301202  0.487332   \n",
       "47        2     0.3    9.0    0.001249  0.484529   \n",
       "2         2     0.9   52.0    0.378091  0.482208   \n",
       "17        4     0.7   26.0    0.321847  0.495995   \n",
       "13  2_3_4_5     0.7   28.0    0.288041  0.478942   \n",
       "5         3     0.5   17.0    0.368825  0.488717   \n",
       "43      3_4     0.1   15.0    0.262486  0.491361   \n",
       "19  2_3_4_6     0.3   11.0    0.052200  0.489992   \n",
       "14        3     0.3   18.0    0.415630  0.497469   \n",
       "\n",
       "                                            filename  \n",
       "10   events.out.tfevents.1730676175.yuriarch.2971.10  \n",
       "23   events.out.tfevents.1730650766.yuriarch.53982.9  \n",
       "47   events.out.tfevents.1730676650.yuriarch.2971.14  \n",
       "2     events.out.tfevents.1730675393.yuriarch.2971.5  \n",
       "17  events.out.tfevents.1730651270.yuriarch.53982.12  \n",
       "13   events.out.tfevents.1730651947.yuriarch.99853.3  \n",
       "5     events.out.tfevents.1730675616.yuriarch.2971.6  \n",
       "43   events.out.tfevents.1730649767.yuriarch.53982.2  \n",
       "19   events.out.tfevents.1730677377.yuriarch.2971.19  \n",
       "14   events.out.tfevents.1730650200.yuriarch.53982.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.analytics import load_tensorboard_logs\n",
    "\n",
    "df = load_tensorboard_logs(\"tb_logs/cnn\").sort_values(\"val_acc\", ascending=False)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_acc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer_name</th>\n",
       "      <th>n_grams</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.781426</td>\n",
       "      <td>0.930071</td>\n",
       "      <td>2048</td>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.239519</td>\n",
       "      <td>0.481192</td>\n",
       "      <td>events.out.tfevents.1730676175.yuriarch.2971.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     val_acc  train_acc  batch_size  hidden_dim  learning_rate optimizer_name  \\\n",
       "10  0.781426   0.930071        2048         500          0.001           Adam   \n",
       "\n",
       "   n_grams dropout  epoch  train_loss  val_loss  \\\n",
       "10       2     0.3   13.0    0.239519  0.481192   \n",
       "\n",
       "                                           filename  \n",
       "10  events.out.tfevents.1730676175.yuriarch.2971.10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cnn_model_configuration = df.head(1)\n",
    "best_cnn_model_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Config on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNClassifier(\n",
      "  (model): CNN(\n",
      "    (embedding): Embedding(16334, 300, padding_idx=0)\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (fc): Linear(in_features=500, out_features=250, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (fc2): Linear(in_features=250, out_features=2, bias=True)\n",
      "  )\n",
      "  (metric): MulticlassAccuracy()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuri/sc4002-nlp-sentiment-classification/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'cnn_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['cnn_model'])`.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from models.CNN import CNNClassifier\n",
    "\n",
    "\n",
    "best_cnn_model_file_name = best_cnn_model_configuration[\"filename\"].item()\n",
    "matched_files = list(Path().rglob(best_cnn_model_file_name))\n",
    "\n",
    "if not matched_files:\n",
    "    print(\"Model checkpoint not found!\")\n",
    "else:\n",
    "    checkpoint_dir = matched_files[0].parent / \"checkpoints\"\n",
    "    checkpoint_files = (\n",
    "        list(checkpoint_dir.glob(\"*.ckpt\")) if checkpoint_dir.exists() else []\n",
    "    )\n",
    "\n",
    "    if not checkpoint_files:\n",
    "        print(\"No checkpoint files found in the checkpoint directory!\")\n",
    "    else:\n",
    "        best_checkpoint = checkpoint_files[0]\n",
    "        best_cnn_model = CNNClassifier.load_from_checkpoint(\n",
    "            best_checkpoint\n",
    "        )\n",
    "        print(best_cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1066/1066 [00:02<00:00, 445.65it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.7879924774169922\n",
      "        test_loss           0.4289623200893402\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.4289623200893402, 'test_acc': 0.7879924774169922}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightning as L\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True)\n",
    "\n",
    "trainer = L.Trainer(accelerator=\"cpu\")\n",
    "trainer.test(best_cnn_model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
