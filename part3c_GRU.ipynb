{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3(c\n",
    ")\n",
    "\n",
    "This notebook will highlight the process, result and insights obtained from allowing updates to the embedding matrix during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "embedding_path = Path(\"models/embedding_matrix_oov.npy\")\n",
    "index_from_word_path = Path(\"models/index_from_word_oov.json\")\n",
    "\n",
    "embedding_matrix = np.load(embedding_path)\n",
    "with index_from_word_path.open() as f:\n",
    "    index_from_word = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text import tokenize\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = tokenize(dataset[\"train\"])\n",
    "val_dataset = tokenize(dataset[\"validation\"])\n",
    "test_dataset = tokenize(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Tokenise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text import token_to_index\n",
    "\n",
    "train_dataset = token_to_index(dataset=train_dataset, index_from_word=index_from_word)\n",
    "val_dataset = token_to_index(dataset=val_dataset, index_from_word=index_from_word)\n",
    "test_dataset = token_to_index(dataset=test_dataset, index_from_word=index_from_word)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])\n",
    "val_dataset = val_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])\n",
    "test_dataset = test_dataset.select_columns([\"label\", \"original_len\", \"indexes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(type=\"torch\")\n",
    "val_dataset.set_format(type=\"torch\")\n",
    "test_dataset.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Optuna to perform heuristic search on optimal configuration when embeddings are updatable during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from utils.train import train_rnn_model_with_parameters\n",
    "\n",
    "_N_TRIALS = 50\n",
    "SEARCH_SPACE = {\n",
    "    \"batch_size\": [2048],\n",
    "    \"learning_rate\": [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    \"optimizer_name\": [\"Adagrad\", \"Adam\"],\n",
    "    # RNN Model Parameters\n",
    "    \"hidden_dim\": [256, 128, 64, 32],\n",
    "    \"num_layers\": [1, 2, 4],\n",
    "    \"sentence_representation_type\": [\"last\", \"average\", \"max\"],\n",
    "    \"bidirectional\" : [False, True],\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", SEARCH_SPACE[\"hidden_dim\"])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", min(SEARCH_SPACE[\"num_layers\"]), max(SEARCH_SPACE[\"num_layers\"]))\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer_name\", SEARCH_SPACE[\"optimizer_name\"])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", SEARCH_SPACE[\"batch_size\"])\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", SEARCH_SPACE[\"learning_rate\"])\n",
    "    sentence_representation_type = trial.suggest_categorical(\"sentence_representation_type\", SEARCH_SPACE[\"sentence_representation_type\"])\n",
    "    bidirectional = trial.suggest_categorical(\"bidirectional\", SEARCH_SPACE[\"bidirectional\"])\n",
    "\n",
    "    \n",
    "    log_message = f\"---------- batch_size_{batch_size}; lr_{learning_rate}; optimizer_{optimizer_name}; hidden_dim_{hidden_dim}; num_layers_{num_layers}; sentence_representation_{sentence_representation_type}; bidirectional_{bidirectional} ----------\"\n",
    "    print(log_message)\n",
    "\n",
    "    val_acc = train_rnn_model_with_parameters(\n",
    "        embedding_matrix=embedding_matrix,\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        optimizer_name=optimizer_name,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        sentence_representation_type=sentence_representation_type,\n",
    "        show_progress=True,\n",
    "        freeze_embedding=False,\n",
    "        log_dir=\"rnn_trainable_embeddings\",\n",
    "        rnn_type=\"GRU\", # biGRU model\n",
    "        bidirectional=bidirectional\n",
    "\n",
    "    )\n",
    "    \n",
    "    return val_acc\n",
    "\n",
    "# Set up the Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=_N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Optuna study\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=_N_TRIALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Load result from all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analytics import load_tensorboard_logs\n",
    "\n",
    "train_results_df = load_tensorboard_logs(log_dir=\"tb_logs/rnn_trainable_embeddings\")\n",
    "\n",
    "train_results_df = train_results_df.sort_values(\n",
    "    by=[\"val_acc\"], ascending=False\n",
    ").reset_index(drop=True)\n",
    "train_results_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Configuration for best trial result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rnn_model_configuration = train_results_df.head(1)\n",
    "best_rnn_model_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analytics import test_top_n_models\n",
    "from models.RNN import RNNClassifier\n",
    "\n",
    "test_results_df = test_top_n_models(train_results_df, RNNClassifier, test_dataset, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
